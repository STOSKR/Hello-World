# ğŸ“ MASTER PLAN - CS2 Agentic Graph System

**Trabajo Fin de MÃ¡ster**: Sistema de Arbitraje Financiero Automatizado con IA AgÃ©ntica

---

## ğŸ“Œ Estado del Proyecto

**âœ… Fase 1 COMPLETADA** - Sistema de scraping funcional en producciÃ³n:
- Scraping automÃ¡tico con Playwright
- Base de datos Supabase (PostgreSQL)
- GitHub Actions (cada 6 horas)
- Sistema anti-ban configurable
- CÃ³digo funcional en `src/`

**ğŸš§ Fase 2 EN CURSO** - MigraciÃ³n a Clean Architecture:
- RefactorizaciÃ³n a `app/` con separaciÃ³n de capas
- ImplementaciÃ³n de principios SOLID
- Tipado estricto con Pydantic

**â³ Fases 3-4 PENDIENTES** - IA AgÃ©ntica:
- LangGraph para orquestaciÃ³n
- Pydantic-AI para validaciÃ³n con LLMs
- Trading autÃ³nomo

---

## ğŸ¯ OBJETIVO

**ROL DE LA IA**: Principal Software Engineer y Arquitecto de IA

**MISIÃ“N**: Refactorizar el sistema existente (`src/`) a Clean Architecture (`app/`) y extenderlo con:
- **LangGraph**: OrquestaciÃ³n y gestiÃ³n de estado
- **Pydantic-AI**: Inteligencia artificial con output estructurado

**ESTÃNDAR**: CÃ³digo de producciÃ³n, Clean Architecture, AsÃ­ncrono y Tipado Estricto

---

## 1. ğŸŒŸ VisiÃ³n y Objetivos

Desarrollar un **pipeline inteligente** donde el dato fluye a travÃ©s de nodos especializados.

### Objetivos Principales

| # | Objetivo | Estado | DescripciÃ³n |
|---|----------|--------|-------------|
| 1 | **DetecciÃ³n en Tiempo Real** | âœ… Completado | Scraping de Steam/Buff163 con Playwright cada 6 horas |
| 2 | **Filtrado MatemÃ¡tico** | âœ… Completado | CÃ¡lculo de ROI, fees, spread con filtros configurables |
| 3 | **ValidaciÃ³n IA** | â³ Pendiente | Validar riesgo usando LLMs (Gemini/GPT) analizando tendencias |
| 4 | **EjecuciÃ³n AutÃ³noma** | â³ Pendiente | Ejecutar operaciones de trading de forma autÃ³noma |

---

## 2. ğŸ› ï¸ Stack TecnolÃ³gico

### âœ… Implementado (Fase 1 - `src/`)

| Componente | TecnologÃ­a | Uso Actual |
|------------|-----------|------------|
| **Lenguaje** | Python 3.11+ | Async/await nativo |
| **Scraping** | Playwright | NavegaciÃ³n headless/visible, anti-detecciÃ³n |
| **Base de Datos** | Supabase (PostgreSQL) | Almacenamiento histÃ³rico de precios |
| **CI/CD** | GitHub Actions | EjecuciÃ³n automÃ¡tica cada 6 horas |
| **ConfiguraciÃ³n** | JSON + dotenv | Presets de trading y credenciales |
| **Logging** | logging estÃ¡ndar | Archivos de log con timestamps |

### ğŸš§ En MigraciÃ³n (Fase 2 - `app/`)

| Componente | TecnologÃ­a | PropÃ³sito |
|------------|-----------|----------|
| **Modelos** | Pydantic | ValidaciÃ³n estricta y type hints |
| **ConfiguraciÃ³n** | pydantic-settings | CentralizaciÃ³n .env + JSON |
| **Logging** | structlog / JSON | Logging estructurado sin emojis |
| **Testing** | pytest + pytest-asyncio | Tests unitarios/integraciÃ³n |

### â³ Por Implementar (Fases 3-4)

| Componente | TecnologÃ­a | PropÃ³sito |
|------------|-----------|----------|
| **OrquestaciÃ³n** | LangGraph | GestiÃ³n de estado y flujo cÃ­clico |
| **Agentes IA** | Pydantic-AI | LLMs con output estructurado |
| **Modelos LLM** | Gemini Flash / GPT-4o-mini | Low latency & cost |
| **Cliente HTTP** | httpx (opcional) | Async HTTP/2 para APIs REST |

---

## 3. ğŸ—ï¸ Arquitectura de Software (Clean Architecture)

**Principio**: El cÃ³digo debe estar desacoplado. Los Nodos del Grafo NO contienen lÃ³gica de negocio compleja, solo orquestan llamadas a Servicios.

### Estructura Actual (Fase 1 - Funcional)

```
src/                        # CÃ³digo legacy funcional
â”œâ”€â”€ scraper.py              # Scraper principal (Playwright)
â”œâ”€â”€ main.py                 # Entrypoint con CLI
â”œâ”€â”€ database.py             # Cliente Supabase
â”œâ”€â”€ config_manager.py       # Gestor de presets
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ extractors/         # Extractores de items/detalles
â”‚   â”œâ”€â”€ filters/            # Filtros de bÃºsqueda
â”‚   â””â”€â”€ utils/              # BrowserManager, FileSaver
â””â”€â”€ utils/
    â””â”€â”€ logger_config.py    # ConfiguraciÃ³n logging

config/
â”œâ”€â”€ scraper_config.json     # ConfiguraciÃ³n general + anti-ban
â”œâ”€â”€ preset_configs.json     # 6 presets de trading + modos anti-ban
â””â”€â”€ schema.sql              # Schema Supabase
```

### Estructura Target (Fase 2-4 - Clean Architecture)

```
app/                        # Nueva arquitectura limpia
â”œâ”€â”€ core/                   # ConfiguraciÃ³n transversal
â”‚   â”œâ”€â”€ config.py           # Settings con pydantic-settings
â”‚   â””â”€â”€ logger.py           # Logger JSON estructurado (sin emojis)
â”œâ”€â”€ domain/                 # LÃ³gica Pura (sin I/O)
â”‚   â”œâ”€â”€ models.py           # Pydantic Models (Skin, MarketData, etc.)
â”‚   â”œâ”€â”€ state.py            # AgentState (LangGraph - Fase 3)
â”‚   â””â”€â”€ rules.py            # FÃ³rmulas (fees, spread, ROI)
â”œâ”€â”€ services/               # Implementaciones concretas
â”‚   â”œâ”€â”€ scraping.py         # LÃ³gica scraping (migrado de src/)
â”‚   â”œâ”€â”€ market_math.py      # CÃ¡lculos financieros
â”‚   â””â”€â”€ storage.py          # Repositorio Supabase async
â”œâ”€â”€ graph/                  # LangGraph (Fases 3-4)
â”‚   â”œâ”€â”€ nodes/              # Scout, Math, Analyst, Trader
â”‚   â”œâ”€â”€ agents/             # Pydantic-AI agents
â”‚   â””â”€â”€ workflow.py         # CompilaciÃ³n del grafo
â””â”€â”€ main.py                 # Entrypoint con DI

src/                        # Mantener por compatibilidad
```

### Flujo de Datos

```
ENTRADA â†’ Scout Node â†’ Math Node â†’ Analyst Node â†’ Trader Node â†’ SALIDA
           (Scraping)   (Filtering)   (AI Risk)      (Execution)
```

---

## 4. ğŸ“‹ Fases de ImplementaciÃ³n (Roadmap)

### âœ… FASE 1: Scraping Base y Almacenamiento (COMPLETADA)

**Objetivo**: Sistema funcional de scraping con almacenamiento persistente.

#### âœ… Logros Completados
- âœ… Scraper con Playwright (headless/visible configurable)
- âœ… IntegraciÃ³n Supabase para historial de precios
- âœ… Sistema de 6 presets de trading configurables
- âœ… GitHub Actions (ejecuciÃ³n automÃ¡tica cada 6 horas)
- âœ… Anti-ban: concurrencia configurable (1-3 items paralelos)
- âœ… Anti-ban: delays aleatorios entre requests
- âœ… Anti-ban: 4 modos (safe/balanced/fast/stealth)
- âœ… Guardado de progreso parcial en interrupciones
- âœ… CÃ¡lculo de fees Steam/Buff, spread, ROI, rentabilidad
- âœ… ExtracciÃ³n de datos detallados (precios, volÃºmenes, listings)
- âœ… Manejo robusto de errores con logging

#### Artefactos Existentes
- `src/scraper.py`: Scraper principal (330 lÃ­neas)
- `src/database.py`: Cliente Supabase
- `src/main.py`: CLI con presets
- `config/scraper_config.json`: Config anti-ban
- `config/preset_configs.json`: Presets trading + anti-ban
- `set_anti_ban_mode.py`: CLI para cambiar modos
- `.github/workflows/`: GitHub Actions configurado

---

### ğŸš§ FASE 2: MigraciÃ³n a Clean Architecture (EN CURSO)

**Objetivo**: Refactorizar cÃ³digo de `src/` a `app/` siguiendo principios SOLID.

**DecisiÃ³n ArquitectÃ³nica (Noviembre 2025)**: Simplificar flujo de datos usando **Dicts para intermedios, Pydantic solo para resultado final**.

#### âœ… Cambios Implementados
- âœ… Eliminados modelos innecesarios: `Skin`, `MarketData`, `PriceData`
- âœ… `ItemExtractor` devuelve `List[Dict]` en lugar de `List[Skin]`
- âœ… `DetailedItemExtractor` recibe `Dict` y devuelve `Dict`
- âœ… `ScrapingService` crea `ScrapedItem` solo al final con `**dict`
- âœ… ValidaciÃ³n Pydantic SOLO en punto final del flujo

**Ventajas de esta arquitectura**:
- Flexibilidad: fÃ¡cil agregar campos sin cambiar modelos
- Performance: sin overhead de validaciÃ³n intermedia
- Scraping-friendly: adaptable a cambios en estructura web
- Menos cÃ³digo: menos modelos = menos mantenimiento

#### Tareas Restantes Restantes
- [ ] Implementar `app/core/logger.py` con logging JSON estructurado (sin emojis)
- [ ] Migrar cÃ¡lculos financieros a `app/domain/rules.py`
  - Fees Steam (13%), Buff (2.5%), cÃ¡lculo ROI, spread
- [ ] Crear `app/services/storage.py` para Supabase
  - Interfaz async real (no sync marcado como async)
- [ ] Implementar tests unitarios para services y domain
- [ ] Actualizar `requirements.txt` (structlog si se usa)

#### Definition of Done
- [x] ItemExtractor devuelve `List[Dict]` en lugar de objetos Pydantic
- [x] DetailedItemExtractor trabaja con `Dict` en lugar de `Skin`
- [x] ScrapingService valida con Pydantic solo al final (ScrapedItem)
- [x] Eliminados modelos innecesarios (Skin, MarketData, PriceData)
- [ ] Logging estructurado sin emojis implementado
- [ ] Tests unitarios para flujo completo de scraping
- [ ] Type hints completos (mypy --strict pasa)
- [ ] `src/` sigue funcional (backward compatibility)
- [ ] DocumentaciÃ³n actualizada en README y MASTER_PLAN

---

### â³ FASE 3: OrquestaciÃ³n con LangGraph (PENDIENTE)

**Objetivo**: Implementar grafo de nodos para flujo de decisiÃ³n.

#### Tareas
- [ ] Definir `AgentState` en `app/domain/state.py`
- [ ] Crear `app/graph/nodes/scout_node.py` (orquesta scraping)
  - Delega a `services/scraping.py`
  - < 15 lÃ­neas, solo orquestaciÃ³n
- [ ] Crear `app/graph/nodes/math_node.py` (filtra por rentabilidad)
  - Usa `domain/rules.py` para cÃ¡lculos
- [ ] Crear `app/graph/workflow.py` (compila grafo)
  - Define aristas Scout â†’ Math
- [ ] Integrar con servicios existentes de Fase 2

#### Definition of Done
- Ejecutar grafo con un skin devuelve estado con precios y profit
- Manejo de errores sin crashes (errores en `state['errors']`)
- Logging estructurado de cada transiciÃ³n de nodo
- Tests de integraciÃ³n del flujo completo

---

### â³ FASE 4: Inteligencia Artificial con Pydantic-AI (PENDIENTE)

**Objetivo**: ValidaciÃ³n de riesgo usando LLMs.

#### Tareas
- [ ] Configurar cliente Gemini Flash / GPT-4o-mini
- [ ] Crear `app/graph/agents/analyst_agent.py` con Pydantic-AI
- [ ] Definir System Prompt ("Trader experto en CS2...")
- [ ] Crear `analyst_node` que consume el agente
  - Input: `state['market_data']` y `state['spread_analysis']`
  - Output: `state['risk_assessment']`
- [ ] Integrar anÃ¡lisis de volatilidad histÃ³rica
- [ ] Integrar anÃ¡lisis de volumen de mercado
- [ ] AÃ±adir `trader_node` (simulado) que ejecuta si riesgo LOW

#### Definition of Done
Sistema devuelve anÃ¡lisis estructurado:
```json
{
  "risk_level": "LOW|MEDIUM|HIGH",
  "confidence": 0.85,
  "reasoning": "Volatilidad baja (3%), volumen alto (200/dÃ­a)...",
  "recommended_action": "BUY|WAIT|SKIP"
}
```
- Operaciones simuladas se guardan en Supabase
- Logs de todas las decisiones del LLM
- Rate limiting para evitar costos excesivos

---

## 5. ğŸ“ GuÃ­a de Estilos y Buenas PrÃ¡cticas

Sigue estas reglas **estrictamente** al generar cÃ³digo.

### 5.1. Tipado y Datos

âœ… **Hacer**:
```python
from typing import Dict, List

# Para datos intermedios: Dict con type hints
async def extract_items(page) -> List[Dict]:
    return [{"name": "AK-47", "price": 10.5}]

# Para datos finales: Pydantic validation
from pydantic import BaseModel

class ScrapedItem(BaseModel):
    item_name: str
    profit_eur: float

def finalize(data: Dict) -> ScrapedItem:
    return ScrapedItem(**data)  # ValidaciÃ³n SOLO aquÃ­
```

âŒ **NO Hacer**:
```python
def extract_items(page):  # Sin tipos
    return ["AK-47", 10.5]  # Sin estructura

class Skin(BaseModel):  # NO para datos intermedios
    name: str

def extract(row) -> Skin:  # ValidaciÃ³n prematura
    return Skin(name=row.text)  # Rompe con cambios web
```

**Reglas**:
- **Datos intermedios**: `Dict` con type hints (`Dict`, `List[Dict]`)
- **Datos finales**: `Pydantic` para validaciÃ³n (ScrapedItem)
- **Return Types**: Todas las funciones deben tener type hinting explÃ­cito
- **RazÃ³n**: Web scraping requiere flexibilidad, validar solo al final

---

### 5.2. LangGraph Patterns

âœ… **Nodos Ligeros** (< 15 lÃ­neas):
```python
async def scout_node(state: AgentState) -> AgentState:
    """Nodo responsable de buscar precios."""
    skin_name = state["target_skin"]
    try:
        market_data = await scraping_service.get_prices(skin_name)
        return {**state, "market_data": market_data}
    except Exception as e:
        return {**state, "errors": [f"Scraping error: {str(e)}"]}
```

**Reglas**:
- Un nodo NO debe tener mÃ¡s de 15 lÃ­neas
- Debe delegar la lÃ³gica a `services/`
- **Manejo de Errores**: No lances excepciones, escribe en `state['errors']`

---

### 5.3. AsincronÃ­a (Asyncio)

âœ… **Correcto**:
```python
async def fetch_prices(skin: str) -> MarketData:
    async with httpx.AsyncClient() as client:
        response = await client.get(f"/api/prices/{skin}")
        return MarketData(**response.json())
```

âŒ **Incorrecto**:
```python
def fetch_prices(skin: str):  # Sin async
    response = requests.get(f"/api/prices/{skin}")  # Bloqueante
    time.sleep(1)  # âŒ Nunca usar time.sleep()
```

**Reglas**:
- Todo I/O (Red, Base de Datos, LLM) debe ser `async/await`
- Nunca uses `time.sleep()`, usa `await asyncio.sleep()`

---

### 5.4. Mantenibilidad

#### InyecciÃ³n de Dependencias

âœ… **Hacer**:
```python
async def scout_node(
    state: AgentState,
    scraper: ScrapingService  # Inyectado
) -> AgentState:
    data = await scraper.get_prices(state["target_skin"])
    return {**state, "market_data": data}
```

âŒ **NO Hacer**:
```python
async def scout_node(state: AgentState) -> AgentState:
    scraper = ScrapingService()  # âŒ Instanciado dentro
    data = await scraper.get_prices(state["target_skin"])
```

#### ConfiguraciÃ³n Centralizada

âœ… **Hacer**:
```python
from app.core.config import settings

api_key = settings.GEMINI_API_KEY
```

âŒ **NO Hacer**:
```python
import os
api_key = os.getenv("GEMINI_API_KEY")  # âŒ En mitad del cÃ³digo
```

---

## 6. ğŸ“š ApÃ©ndice: Ejemplos de CÃ³digo Esperado

### Ejemplo 1: Nodo de LangGraph

```python
from typing import Dict, Any
from app.domain.state import AgentState
from app.services.scraping import ScrapingService

async def scout_node(state: AgentState) -> AgentState:
    """
    Nodo responsable de extraer precios de mercados.
    
    Input: state['target_skin']
    Output: state['market_data'] or state['errors']
    """
    skin_name = state["target_skin"]
    
    try:
        # Delegamos al servicio (Clean Code)
        market_data = await ScrapingService.get_prices(skin_name)
        return {**state, "market_data": market_data}
    
    except Exception as e:
        # No crash, agregamos error al estado
        return {**state, "errors": [f"Scraping error: {str(e)}"]}
```

---

### Ejemplo 2: Agente Pydantic-AI

```python
from pydantic import BaseModel
from pydantic_ai import Agent
from app.domain.models import RiskAnalysis

class SpreadAnalysis(BaseModel):
    skin_name: str
    spread_percent: float
    volume_24h: int
    volatility: float

# Definir el agente con output estructurado
analyst = Agent(
    'google-gla:gemini-flash',
    result_type=RiskAnalysis,  # Fuerza respuesta JSON estructurada
    system_prompt=(
        "Eres un trader experto en CS2 skins. "
        "Analiza la volatilidad histÃ³rica y el volumen de mercado. "
        "Decide si es seguro ejecutar la operaciÃ³n de arbitraje."
    )
)

async def analyst_node(state: AgentState) -> AgentState:
    """
    Nodo que valida el riesgo usando IA.
    
    Input: state['spread_analysis']
    Output: state['risk_assessment']
    """
    try:
        # El LLM recibe contexto estructurado
        analysis = state['spread_analysis']
        
        result = await analyst.run(
            f"Analiza esta oportunidad: "
            f"Skin: {analysis.skin_name}, "
            f"Spread: {analysis.spread_percent}%, "
            f"Volumen 24h: {analysis.volume_24h}, "
            f"Volatilidad: {analysis.volatility}"
        )
        
        return {**state, "risk_assessment": result.data}
    
    except Exception as e:
        return {**state, "errors": [f"AI analysis error: {str(e)}"]}
```

---

### Ejemplo 3: Servicio de Scraping

```python
import httpx
from typing import Optional
from app.domain.models import MarketData
from app.core.config import settings
from app.core.logger import logger

class ScrapingService:
    """Servicio asÃ­ncrono para extraer precios de mercados."""
    
    @staticmethod
    async def get_prices(skin_name: str) -> MarketData:
        """
        Extrae precios de Steam y Buff163.
        
        Args:
            skin_name: Nombre del skin (ej: "AK-47 | Redline")
            
        Returns:
            MarketData con precios de ambos mercados
            
        Raises:
            httpx.HTTPError: Si la peticiÃ³n falla
        """
        async with httpx.AsyncClient(timeout=30.0) as client:
            # Steam
            steam_response = await client.get(
                f"{settings.STEAM_API_URL}/market/priceoverview",
                params={"market_hash_name": skin_name}
            )
            steam_response.raise_for_status()
            steam_data = steam_response.json()
            
            # Buff163
            buff_response = await client.get(
                f"{settings.BUFF_API_URL}/market/goods",
                params={"game": "csgo", "search": skin_name}
            )
            buff_response.raise_for_status()
            buff_data = buff_response.json()
            
            logger.info(f"Prices fetched for {skin_name}")
            
            return MarketData(
                skin_name=skin_name,
                steam_price=float(steam_data['lowest_price']),
                buff_price=float(buff_data['data']['items'][0]['sell_min_price']),
                timestamp=datetime.utcnow()
            )
```

---

### Ejemplo 4: Modelo de Dominio

```python
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional, Literal

# NOTA: Solo modelos para resultado final y configuraciÃ³n
# Datos intermedios usan Dict simple

class ScrapedItem(BaseModel):
    """Resultado final del scraping (ÃšNICA validaciÃ³n Pydantic)."""
    item_name: str
    url: Optional[str] = None
    buff_url: Optional[str] = None
    steam_url: Optional[str] = None
    
    buff_avg_price_eur: float = Field(..., gt=0)
    steam_avg_price_eur: float = Field(..., gt=0)
    
    profit_eur: float
    profitability_ratio: float
    
    scraped_at: datetime = Field(default_factory=datetime.utcnow)

class FilterConfig(BaseModel):
    """ConfiguraciÃ³n de filtros."""
    min_price: float = Field(default=20.0, ge=0)
    max_price: Optional[float] = None
    min_volume: int = Field(default=40, ge=0)
    platforms: dict[str, bool] = Field(default={"BUFF": True})

class RiskAnalysis(BaseModel):
    """Resultado del anÃ¡lisis de riesgo por IA (Fase 4)."""
    risk_level: Literal["LOW", "MEDIUM", "HIGH"]
    confidence: float = Field(..., ge=0.0, le=1.0)
    reasoning: str
    recommended_action: Literal["BUY", "WAIT", "SKIP"]

class AgentState(BaseModel):
    """Estado compartido del grafo LangGraph (Fase 3)."""
    target_skin: str
    market_data: Optional[dict] = None  # Dict, no Pydantic
    spread_analysis: Optional[dict] = None
    risk_assessment: Optional[RiskAnalysis] = None
    errors: list[str] = Field(default_factory=list)
```

---

## 7. âœ… Checklist de Calidad

Antes de considerar una fase completada, verificar:

### Code Quality
- [ ] Todos los archivos tienen docstrings
- [ ] Todas las funciones tienen type hints
- [ ] No hay `print()`, solo logging estructurado
- [ ] No hay `time.sleep()` en cÃ³digo async
- [ ] ValidaciÃ³n Pydantic SOLO en datos finales

### Architecture
- [ ] Los nodos de LangGraph son < 15 lÃ­neas
- [ ] La lÃ³gica de negocio estÃ¡ en `services/`
- [ ] Los modelos estÃ¡n en `domain/`
- [ ] La configuraciÃ³n estÃ¡ centralizada en `core/`

### Testing
- [ ] Existe un test para cada fase
- [ ] Los tests son async (`pytest-asyncio`)
- [ ] Coverage > 70%

### Documentation
- [ ] README actualizado con la fase completada
- [ ] Ejemplos de uso en `examples/`
- [ ] Comentarios en cÃ³digo complejo

---

## 8. ğŸš€ Comandos de Desarrollo

```bash
# Setup inicial
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# Desarrollo
python app/main.py --skin "AK-47 | Redline"

# Testing
pytest tests/ -v
pytest tests/ --cov=app --cov-report=html

# Linting
ruff check app/
mypy app/

# Docker (Fase 4)
docker-compose up -d mongodb
```

---

## 9. ğŸ“Š MÃ©tricas de Ã‰xito

| MÃ©trica | Objetivo | Fase |
|---------|----------|------|
| **Latencia Scraping** | < 2 segundos | Fase 1 |
| **PrecisiÃ³n CÃ¡lculos** | 100% (tests) | Fase 1 |
| **Latencia Grafo** | < 5 segundos | Fase 2 |
| **Latencia LLM** | < 3 segundos | Fase 3 |
| **Disponibilidad** | > 99% | Fase 4 |
| **ROI Real** | > 5% (simulado) | Fase 4 |

---

**ğŸ“ Este documento es la guÃ­a maestra para el desarrollo del TFM.**

Ãšltima actualizaciÃ³n: Noviembre 2025
